{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pathlib\n",
    "from time import time\n",
    "from tensorflow_docs import modeling\n",
    "import tensorflow_io as tfio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   try:\n",
    "#     # Currently, memory growth needs to be the same across GPUs\n",
    "#     for gpu in gpus:\n",
    "#       tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#     logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#     print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#   except RuntimeError as e:\n",
    "#     # Memory growth must be set before GPUs have been initialized\n",
    "#     print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version:  2.4.1\n",
      "Number of GPU available:  1\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "print(\"TensorFlow Version: \", tf.__version__)\n",
    "print(\"Number of GPU available: \", len(tf.config.experimental.list_physical_devices(\"GPU\")))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 36\n",
    "IMG_WIDTH = 36\n",
    "BATCH_SIZE = 64\n",
    "val_fraction = 15\n",
    "max_epochs = 100\n",
    "augment_degree = 0.10\n",
    "shuffle_buffer_size = 2500"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# file_path = r'\\\\babyserverdw3\\Pei-Hsun Wu\\Collaboration\\Amit Agarwal\\210120 testing stitching algorith on mouse brain fluorescence image\\for training\\set4\\Ast\\trainim00001.tif'\n",
    "# img = tf.io.read_file(file_path)\n",
    "# img = tfio.experimental.image.decode_tiff(img)\n",
    "# img.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# img2 = tfio.experimental.color.rgba_to_rgb(img)\n",
    "# img2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# channels = tf.unstack (img,num=4, axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# image    = tf.stack   ([channels[0], channels[1], channels[2]], axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# images = os.path.join(*[train_data_dir,'Ast','*.tif'])\n",
    "# list_ds = tf.data.Dataset.list_files(images)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# for file_path in list_ds.take(2):\n",
    "#     img = tf.io.read_file(file_path)\n",
    "#     img = tfio.experimental.image.decode_tiff(img)\n",
    "#     img = tfio.experimental.color.rgba_to_rgb(img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# labeled_ds = list_ds.map(read_and_label, num_parallel_calls=AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# file_path = r'\\\\babyserverdw3\\Pei-Hsun Wu\\Collaboration\\Amit Agarwal\\210120 testing stitching algorith on mouse brain fluorescence image\\for training\\set4\\Ast\\trainim00001.tif'\n",
    "# parts = tf.strings.split(file_path, os.path.sep)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# parts[-2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# one_hot = parts[-2] == CLASS_NAMES\n",
    "# tf.argmax(one_hot)\n",
    "\n",
    "# ans = tf.reshape(tf.where(parts[-2] == CLASS_NAMES), [])\n",
    "# ans"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def read_and_label(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = tf.io.read_file(file_path)\n",
    "    # img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tfio.experimental.image.decode_tiff(img)\n",
    "    # img = tfio.experimental.color.rgba_to_rgb(img)\n",
    "    channels = tf.unstack (img, num=4, axis=-1)\n",
    "    img  = tf.stack   ([channels[0], channels[1], channels[2]], axis=-1)\n",
    "    # img = tf.image.random_hue(img, max_delta=augment_degree, seed=5)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "    return img, label\n",
    "\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    one_hot = parts[-2] == CLASS_NAMES\n",
    "    return tf.argmax(one_hot)\n",
    "\n",
    "    # return tf.reshape(tf.where(parts[-2] == CLASS_NAMES), [])\n",
    "\n",
    "# def augment(image, label):\n",
    "#     degree = augment_degree\n",
    "#     if degree == 0:\n",
    "#         return image, label\n",
    "#     image = tf.image.random_hue(image, max_delta=degree, seed=5)\n",
    "#     image = tf.image.random_contrast(image, 1-degree, 1+degree, seed=5)  # tissue quality\n",
    "#     image = tf.image.random_saturation(image, 1-degree, 1+degree, seed=5)  # stain quality\n",
    "#     image = tf.image.random_brightness(image, max_delta=degree)  # tissue thickness, glass transparency (clean)\n",
    "#     image = tf.image.random_flip_left_right(image, seed=5)  # cell orientation\n",
    "#     image = tf.image.random_flip_up_down(image, seed=5)  # cell orientation\n",
    "#     image = tf.image.random_crop(image, [96,96,3])\n",
    "#     return image, label\n",
    "\n",
    "def prepare(data_dir):\n",
    "    tmp = [0]\n",
    "    for idx,CLASS in enumerate(CLASS_NAMES):\n",
    "        images = os.path.join(*[data_dir,CLASS,'*.tif'])\n",
    "        list_ds = tf.data.Dataset.list_files(images)\n",
    "        labeled_ds = (list_ds\n",
    "                      .map(read_and_label, num_parallel_calls=AUTOTUNE)\n",
    "                      )\n",
    "        if tmp[0] == 0:\n",
    "            tmp[0] = labeled_ds\n",
    "        else:\n",
    "            labeled_ds = tmp[0].concatenate(labeled_ds)\n",
    "            tmp[0] = labeled_ds\n",
    "    return tmp[0].shuffle(shuffle_buffer_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "['Ast', 'Neu', 'Oth']"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_dir = r'\\\\babyserverdw3\\Pei-Hsun Wu\\Collaboration\\Amit Agarwal\\210120 testing stitching algorith on mouse brain fluorescence image\\for training\\set14_scale9to36_cortex_puff'\n",
    "\n",
    "train_data_dir = pathlib.Path(train_data_dir)\n",
    "CLASS_NAMES = np.array([item.name for item in train_data_dir.glob('*') if not item.name.endswith((\".mat\",\".DS_store\",\".png\"))])\n",
    "CLASS_NAMES = sorted(CLASS_NAMES, key=str.lower) #sort alphabetically case-insensitive\n",
    "CLASS_NAMES"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "train_labeled_ds = prepare(train_data_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size :  18000\n",
      "validation size:  2700\n",
      "training set size after split :  15300\n"
     ]
    }
   ],
   "source": [
    "# train_image_count = len(list(train_labeled_ds))\n",
    "train_image_count = tf.data.experimental.cardinality(train_labeled_ds).numpy()\n",
    "print('training set size : ', train_image_count)\n",
    "val_image_count = train_image_count // 100 * val_fraction\n",
    "print('validation size: ', val_image_count)\n",
    "train_image_count2 = train_image_count-val_image_count\n",
    "print('training set size after split : ', train_image_count2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step # 239\n",
      "validation step # 42\n"
     ]
    }
   ],
   "source": [
    "STEPS_PER_EPOCH = train_image_count2 // BATCH_SIZE\n",
    "VALIDATION_STEPS = val_image_count // BATCH_SIZE\n",
    "print('train step #',STEPS_PER_EPOCH)\n",
    "print('validation step #',VALIDATION_STEPS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "for idx, elem in enumerate(train_labeled_ds.take(64)):\n",
    "    img = elem[0]\n",
    "    label = elem[1]\n",
    "    ax = plt.subplot(8,8,idx+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(CLASS_NAMES[label].title())\n",
    "    plt.axis('off')\n",
    "target = 'logs'\n",
    "if not os.path.exists(target): os.mkdir(target)\n",
    "figname = 'augmented_dataset_{}.png'.format(str(round(augment_degree*100)))\n",
    "plt.savefig(os.path.join(target,figname))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "train_labeled_ds = train_labeled_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "train_ds = (train_labeled_ds\n",
    "            .skip(val_image_count)\n",
    "            .shuffle(buffer_size=shuffle_buffer_size)\n",
    "            # .repeat()\n",
    "            .batch(BATCH_SIZE)\n",
    "            .prefetch(buffer_size=AUTOTUNE)\n",
    "            )\n",
    "val_ds = (train_labeled_ds\n",
    "          .take(val_image_count)\n",
    "          # .repeat()\n",
    "          .batch(BATCH_SIZE)\n",
    "          .prefetch(buffer_size=AUTOTUNE))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_dir = pathlib.Path('logs')\n",
    "\n",
    "def get_callbacks(name):\n",
    "    return [\n",
    "        modeling.EpochDots(),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_categorical_crossentropy',\n",
    "                                         patience=50, restore_best_weights=True),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir/name, histogram_freq=1),\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=log_dir/name/\"{}/cp.ckpt\".format(name),\n",
    "                                           verbose=0,\n",
    "                                           monitor='val_sparse_categorical_crossentropy',\n",
    "                                           save_weights_only=True,\n",
    "                                           save_best_only=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_categorical_crossentropy',\n",
    "                                             factor=0.1, patience=10, verbose=0, mode='auto',\n",
    "                                             min_delta=0.0001, cooldown=0, min_lr=0),\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compilefit(model, name, max_epochs, train_ds, val_ds):\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[tf.keras.losses.CategoricalCrossentropy(from_logits=True), 'accuracy'])\n",
    "    model_history = model.fit(train_ds,\n",
    "                              steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                              epochs=max_epochs,\n",
    "                              verbose=1,\n",
    "                              validation_data=val_ds,\n",
    "                              callbacks=get_callbacks(name),\n",
    "                              validation_steps=VALIDATION_STEPS,\n",
    "                              use_multiprocessing=True\n",
    "                              )\n",
    "    # namename = os.path.dirname(name)\n",
    "    # if not os.path.isdir(os.path.abspath(namename)):\n",
    "    #     os.mkdir(os.path.abspath(namename))\n",
    "    # if not os.path.isdir(os.path.abspath(name)):\n",
    "    #     os.mkdir(os.path.abspath(name))\n",
    "    # if not os.path.isfile(pathlib.Path(name) / 'full_model.h5'):\n",
    "    #     try:\n",
    "    #         model.save(pathlib.Path(name) / 'full_model.h5')\n",
    "    #     except:\n",
    "    #         print('model not saved?')\n",
    "    return model_history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "from tensorflow.keras import layers\n",
    "model = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(3)\n",
    "])\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])\n",
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=3\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate(val_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate(train_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = time()\n",
    "# #min input size 76x76\n",
    "MobileNetV2_base = tf.keras.applications.MobileNetV2(input_shape=(96, 96, 3),\n",
    "                                            pooling=None,\n",
    "                                            include_top=False,\n",
    "                                            weights='imagenet'\n",
    "                                            )\n",
    "\n",
    "MobileNetV2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    MobileNetV2_base,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "histories={}\n",
    "histories['mobilenetv2_01'] = compilefit(MobileNetV2, 'mobilenetv2_01', max_epochs, train_ds, val_ds)\n",
    "\n",
    "end = time()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}